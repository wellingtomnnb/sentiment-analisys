{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Carregamento de dados\n",
    "import pandas as pd\n",
    "df= pd.read_csv('../dados/data_polarity.csv', low_memory=False, index_col=[0])\n",
    "\n",
    "print(\";---------------------;\")\n",
    "print(\"|  Dados Carregados!  |\")\n",
    "print(\"|---------------------|\")\n",
    "print(\"|  df: %d         |\" %len(df))\n",
    "print(\";---------------------;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# An√°lise de Sentimentos com custom_vader\n",
    "import sys\n",
    "if '../' not in sys.path: sys.path.append('../')\n",
    "from models.custom_vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sia = SentimentIntensityAnalyzer(\"../dados/custom_vader_lexicon.txt\")\n",
    "print(sia.polarity_scores('eu gostaria ir ao mercado comprar p√£o'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# criando fun√ßoes\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import html\n",
    "import unidecode\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stopwords = list()\n",
    "    try: stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "    except: nltk.download('stopwords')\n",
    "    stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "    stopwords += ['oi', 'ola', 'opa', 'oie', 'oii', 'oiee', 'oin', 's√≥', 'so']\n",
    "    stopwords = [w for w in stopwords if w not in ['mas', 'muito']]\n",
    "    reg_caracters='\\!|\\\"|\\#|\\$|\\%|\\&|\\|\\'|\\(|\\)|\\*|\\+|\\,|\\.|\\/|\\n|\\:|\\;|\\<|\\=|\\>|\\?|\\@|\\[|\\\\|\\]|\\^|\\_|\\`|\\{\\|\\}|\\~|[0-9]*'\n",
    "    remove_acents = lambda sentence: ' '.join([unidecode.unidecode(s) if s.isalnum() else s for s in sentence.split()])\n",
    "    \n",
    "    # remove link do texto\n",
    "    text = re.sub(r'http\\S+', '', text) \n",
    "    # adiciona espa√ßo no inicio e final do hex-emoji\n",
    "    text = text.replace(\"&#x\", \" &#x\").replace(';', '; ') \n",
    "    # transforma o hex-emoji em emoji\n",
    "    text=html.unescape(text)\n",
    "    # remove caracteres especiais do texto\n",
    "    text = re.sub(reg_caracters, \"\", text)\n",
    "    # remove acentos das palavras preservando \n",
    "    text = remove_acents(text)\n",
    "\n",
    "    return \" \".join([s for s in text.split() if s not in stopwords])\n",
    "\n",
    "condictions = lambda pol: [pol < -.45, -.45 <= pol < -.2, -.2 <= pol < .2, .2 <= pol < .45, pol > .45]\n",
    "describes_emojis = {'negativo': \"üò°\", 'irrazoavel': \"üôÅ\", 'neutro': \"üòê\", 'razoavel': \"üôÇ\", 'positivo': \"ü§©\"}\n",
    "\n",
    "\n",
    "get_polarity = lambda sentence: sia.polarity_scores(sentence, prin_not_lex=False)[0][\"compound\"]\n",
    "get_sentence_size = lambda sentence: len(remove_stopwords(sentence).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An√°lise das primeiras 1k msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisando msgs\n",
    "\n",
    "test = df[df['from_me']==0].head(1000).copy()\n",
    "test = test[['protocolo', 'log_texto', 'from_me', 'emojis']]\n",
    "test['polarity'] = test['log_texto'].apply(get_polarity)\n",
    "test['sentence_size'] = test['log_texto'].apply(get_sentence_size)\n",
    "test['class'] = test[\"polarity\"].apply(lambda p: np.select(condictions(p), [*describes_emojis.keys()]) if p is not None else 'indefinido')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores(remove_stopwords(test.log_texto.iat[0]))\n",
    "remove_stopwords(test.log_texto.iat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"class\"].value_counts()\n",
    "test[test[\"class\"] == \"negativo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphs\n",
    "import plotly.graph_objects as go\n",
    "from models.graph_tools import Graph\n",
    "\n",
    "# fig=Graph(test, \"An√°lise de Polaridade por qtd. de Palavras\", is_subplot=True, cols=2, cols_width=[.15,.85], rows=1, row_width=[1])\n",
    "fig=Graph(test, \"An√°lise de Polaridade por qtd. de Palavras\")\n",
    "fig.line('sentence_size', ['polarity'], modes=['markers'], \n",
    "    marker_colorscale='magenta', \n",
    "    hovertemplate='p:%{y:,.2f}%<br>w:%{x}'\n",
    ")\n",
    "fig.show().update_layout(\n",
    "    paper_bgcolor='rgba(230,230,230,230)', \n",
    "    # yaxis={'title': \"Polaridade\", 'range': [-1, 1]},\n",
    "    xaxis={\"title\":\"Qnd.Palavras na Frase\"},\n",
    "    title_x=.5\n",
    ")\n",
    "\n",
    "# fig.show().update_layout(yaxis_showticklabels=True, yaxis2_showticklabels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig=Graph(test, \"An√°lise de Polaridade por qtd. de Palavras\")\n",
    "\n",
    "fig.show().update_layout(\n",
    "    paper_bgcolor='rgba(230,230,230,230)', \n",
    "    # yaxis={'title': \"Polaridade\", 'range': [-1, 1]},\n",
    "    xaxis={\"title\":\"Qnd.Palavras na Frase\"},\n",
    "    title_x=.5\n",
    ")\n",
    "fig.show().add_trace(\n",
    "    go.Box(\n",
    "        y=test.query('polarity > .2')['sentence_size'], \n",
    "        marker_color=\"seagreen\", boxpoints=False, \n",
    "        name='positivos', jitter=0.5, pointpos=-0, boxmean=True\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show().add_trace(\n",
    "    go.Box(\n",
    "        y=test[test.polarity.between(-.2, .2)]['sentence_size'], \n",
    "        # y=test.query('polarity < -.2')['sentence_size'], \n",
    "        marker_color=\"steelblue\", boxpoints=False, \n",
    "        name='neutros', jitter=.5, pointpos=-0, boxmean=True\n",
    "    )\n",
    ")\n",
    "fig.show().add_trace(\n",
    "    go.Box(\n",
    "        y=test.query('polarity < -.2')['sentence_size'], \n",
    "        marker_color=\"#FF851B\", boxpoints=False, \n",
    "        name='negativos', jitter=.5, pointpos=-0, boxmean=True\n",
    "    )\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise de Sentimentos com custom_vader\n",
    "import sys\n",
    "if '../' not in sys.path: sys.path.append('../')\n",
    "from models.custom_vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sia = SentimentIntensityAnalyzer(\"../dados/custom_vader_lexicon.txt\", \n",
    "  stopwords_file = \"/home/dba/Documentos/nlp-api/dados/custom_stopwords.txt\")\n",
    "\n",
    "sentences = [\n",
    "  {\"msg_id\": 1, \"msg\": 'Me orientaram a entrar em contato com voc√™s.'},\n",
    "  {\"msg_id\": 2, \"msg\": 'Adorei o atendimento daquele rapazinho'},\n",
    "  {\"msg_id\": 3, \"msg\": 'Na verdade vou fazer o cancelamento do meu plano'},\n",
    "  {\"msg_id\": 4, \"msg\": 'Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam magna pretium vehicula.'}\n",
    "]\n",
    "\n",
    "res = [\n",
    "  {\"msg_id\": 1, \"polarity\": 0, \"describe\": \"neutro\", \"status\": True},\n",
    "  {\"msg_id\": 2, \"polarity\": 0.875, \"describe\": \"positivo\", \"status\": True},\n",
    "  {\"msg_id\": 3, \"polarity\": -0.3818, \"describe\": \"irrazoavel\", \"status\": True},\n",
    "  {\"msg_id\": 4, \"describe\": \"indefinido\", \"status\": False}\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, Request\n",
    "from routes.unit_polarity import SucessResponse, ValidationErrorResponse, ServerErrorResponse, get\n",
    "\n",
    "# An√°lise de Sentimentos com custom_vader\n",
    "condictions = lambda pol: [pol is None, pol < -.45, -.45 <= pol < -.2, -.2 <= pol < .2, .2 <= pol < .45, pol > .45]\n",
    "describes_emojis = {\"indefinido\": \"üòµ‚Äçüí´\", 'negativo': \"üò°\", 'irrazoavel': \"üôÅ\", 'neutro': \"üòê\", 'razoavel': \"üôÇ\", 'positivo': \"ü§©\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from fastapi.responses import JSONResponse\n",
    "\n",
    "\n",
    "def __loop_searches(sentences:list) -> list:\n",
    "    \"\"\" ## obtem a polaridade para cada senten√ßa\n",
    "    @sentences: lista de senten√ßas;\n",
    "    \"\"\"\n",
    "\n",
    "    result = []\n",
    "    for sentence in sentences:\n",
    "        response = json.loads(get(Request, sentence['msg'], sia, condictions, describes_emojis).body)\n",
    "        response['msg_id'] = sentence['msg_id']\n",
    "        result.append(response)\n",
    "\n",
    "    return result\n",
    "\n",
    "def __concat_sentences(sentences: list, results: list) -> list:\n",
    "    \"\"\" \n",
    "    ## obtem a polaridade de todas senten√ßas juntas\n",
    "    ### e retorna uma string concatenada\n",
    "    @sentences: lista de senten√ßas;\n",
    "    @results: lista de resultados da obten√ß√£o da polaridade das senten√ßas\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.DataFrame(sentences).set_index('msg_id').join(pd.DataFrame(results).set_index('msg_id'))\n",
    "    conversation = ' '.join([s.msg for i, s in df.iterrows() if s.sucess])\n",
    "    return conversation\n",
    "    \n",
    "def multi_polarity(request: Request, sentences: list, sia, condictions: list, describes_emojis: list):\n",
    "    \"\"\" \n",
    "    ## Consulta Multipla de Polaridade de Senten√ßa\n",
    "    request example: \\n\n",
    "    ```\n",
    "    sentences = [\n",
    "        {\"msg_id\": 1, \"msg\": 'Me orientaram a entrar em contato com voc√™s.'},\n",
    "        {\"msg_id\": 4, \"msg\": 'Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam magna pretium vehicula.'}\n",
    "    ]\n",
    "\n",
    "    multi_polarity(sentences)\n",
    "\n",
    "    >> [\n",
    "         {'event': 'unit_polarity','sucess': True,'polarity': 0.3182, 'describe': 'razoavel', 'describe_emoji': 'üôÇ', 'msg_id': 1},\n",
    "         {'event': 'unit_polarity','sucess': False, 'describe': 'indefinido', 'describe_emoji': 'üòµ', 'msg_id': 4},\n",
    "         {'event': 'multi_polarity','sucess': False, 'describe': 'indefinido', 'describe_emoji': 'üòµ', 'msg_id': 4},\n",
    "       ]\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    try: \n",
    "        sentences_result = __loop_searches(sentences)\n",
    "        sentence = __concat_sentences(sentences, sentences_result)\n",
    "        result = get(Request, sentence, sia, condictions, describes_emojis)\n",
    "\n",
    "        response_body = json.loads(result.body)\n",
    "        response_body['event'] = \"multi_polarity\"\n",
    "        response_body['sentences'] = sentences_result\n",
    "        response_body = json.dumps(response_body)\n",
    "\n",
    "        result.body = str(response_body)\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e: \n",
    "        response = {\"event\": \"multi_polarity\", \"sucess\": False}\n",
    "        response[\"describe\"] = str(e)\n",
    "        # __log(sentence, None, e, request)\n",
    "        return JSONResponse(status_code=500, content=response)\n",
    "\n",
    "\n",
    "a=multi_polarity(Request, sentences, sia, condictions, describes_emojis)\n",
    "json.loads(a.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores(\"Eu n√£o gostei do hotel. A cama era ruim.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    {\"sentence\": 'Me orientaram a entrar em contato com voc√™s.'},\n",
    "    {\"sentence\": 'Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam magna pretium vehicula.'}\n",
    "]\n",
    "\n",
    "a= {\n",
    "    \"event\": \"unit_polarity\",\n",
    "    \"sucess\": False,\n",
    "    \"polarity\": 0.3182,\n",
    "    \"describe\": \"razoavel\",\n",
    "    \"describe_emoji\": \"ÔøΩ\",\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(sentences).join(pd.DataFrame([a]))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= {\n",
    "    \"event\": \"unit_polarity\",\n",
    "    \"sucess\": False,\n",
    "    \"polarity\": 0.3182,\n",
    "    \"describe\": \"razoavel\",\n",
    "    \"msg_id\": 1\n",
    "}\n",
    "pd.DataFrame([a])[\"sucessw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=[\n",
    "  {\"sentence\": \"Me orientaram a entrar em contato com voc√™s.\"},\n",
    "  {\"sentence\": \"Adorei o atendimento daquele rapazinho\"},\n",
    "  {\"sentence\": \"Na verdade vou fazer o cancelamento do meu plano\"},\n",
    "  {\"sentence\": \"Na verdade vou fazer o cancelamento do meu plano\"},\n",
    "]\n",
    "\n",
    "not all(\"sentence\" in s.keys() for s in sentences)\n",
    "\n",
    "type(1) is not list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "import json\n",
    "\n",
    "connection = http.client.HTTPSConnection('192.168.0.41', 8560, timeout=10)\n",
    "headers = {'Content-type': 'application/json'}\n",
    "\n",
    "foo = {'text': 'Hello world github/linguist#1 **cool**, and #1!'}\n",
    "json_foo = json.dumps(foo)\n",
    "\n",
    "connection.request('GET', '/polarity/unique/?sentence', json_foo, headers, verify=False)\n",
    "\n",
    "response = connection.getresponse()\n",
    "print(response.read().decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testes Unit√°rios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "headers = {'Content-type': 'application/json'}\n",
    "\n",
    "sentences= [\n",
    "  {\"sentence\": \"Me orientaram a entrar em contato com voc√™s.\"},\n",
    "  {\"sentence\": \"Adorei o atendimento daquele rapazinho\"},\n",
    "  {\"sentencae\": \"Na verdade vou fazer o cancelamento do meu plano\"},\n",
    "]\n",
    "\n",
    "all_invalid_keys= None\n",
    "\n",
    "sentence = \"Adorei o atendimento daquele rapazinho\"\n",
    "\n",
    "\n",
    "body = str(all_invalid_keys).replace(\"'\", '\"').encode()\n",
    "\n",
    "result = requests.get(f'http://192.168.0.41:8560/v1/polarity/unique/?sentence={sentence}')\n",
    "# result = requests.post('http://192.168.0.41:8560/v1/polarity/list' , body, headers=headers)\n",
    "\n",
    "print(result.status_code)\n",
    "\n",
    "print(json.loads(result.content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = requests.get(f'http://192.168.0.41:8560/v1/polarity/unique/?sentence={sentence}')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grequests\n",
    "\n",
    "url = \"http://192.168.0.41:8560/v1/polarity/unique\"\n",
    "\n",
    "valids_sentences= [\n",
    "    \"1 Me orientaram a entrar em contato com voc√™s.\",\n",
    "    \"2 Adorei o atendimento daquele rapazinho\",\n",
    "    \"3 Na verdade vou fazer o cancelamento do meu plano\"\n",
    "]\n",
    "\n",
    "invalids_sentences = [\"4\", '', 'None']\n",
    "\n",
    "valids_urls = [f'{url}/?sentence={s}' for s in valids_sentences] * 3\n",
    "invalids_urls = [f'{url}/?sentence={s}' for s in invalids_sentences] * 3\n",
    "\n",
    "rs = (grequests.get(u, gtimeout=3) for u in invalids_urls)\n",
    "results = grequests.map(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_host=\"192.168.0.41\"\n",
    "port_host=8560\n",
    "route= \"v1/polarity/unique\"\n",
    "route_list= \"v1/polarity/list\"\n",
    "url = f'http://{ip_host}:{port_host}/{route_list if route_list[0] != \"/\" else route_list[1:]}'\n",
    "headers = {'Content-type': 'application/json'}\n",
    "\n",
    "\n",
    "# MODEL\n",
    "multi_valid_sentences= [\n",
    "    {\"sentence\": \"Me orientaram a entrar em contato com voc√™s.\"},\n",
    "    {\"sentence\": \"Adorei o atendimento daquele rapazinho\"},\n",
    "    {\"sentence\": \"Na verdade vou fazer o cancelamento do meu plano\"},\n",
    "] \n",
    "\n",
    "multi_invalid_sentences= [\n",
    "    {\"sentence\": \"11111111111111\"},\n",
    "    {\"sentence\": \"None\"},\n",
    "    {\"sentence\": \"\"},\n",
    "] \n",
    "\n",
    "multi_invalid_keys= [\n",
    "    {\"wrog_key1\": \"Me orientaram a entrar em contato com voc√™s.\"},\n",
    "    {\"wrog_key2\": \"Adorei o atendimento daquele rapazinho\"},\n",
    "    {\"wrog_key3\": \"Na verdade vou fazer o cancelamento do meu plano\"},\n",
    "] \n",
    "\n",
    "results = []\n",
    "for i, body in enumerate([multi_valid_sentences, multi_invalid_sentences, multi_invalid_keys]):\n",
    "    body = str(body).replace(\"'\", '\"').encode()\n",
    "\n",
    "    rs = (grequests.post(link, data=body, headers=headers) for link in [url]*500) \n",
    "    results = grequests.map(rs)\n",
    "\n",
    "    assert not any([r is None for r in results]), \"Some request failed\"\n",
    "\n",
    "    if i == 0: assert all([r.status_code == 200 for r in results]), \"All state codes should be 200\"\n",
    "    if i in [1,2]: assert all([400 <= r.status_code <= 406 for r in results]), \"All state codes should be between 400~499\"\n",
    "\n",
    "df=pd.DataFrame({'reqs':[r.elapsed.total_seconds()  if r is not None else None for r in results], 'a': [1]*len(results)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'reqs':[r.elapsed.total_seconds()  if r is not None else None for r in results], 'a': [1]*len(results)})\n",
    "df.reqs.max()\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.line(df.reset_index(), x=\"index\", y=\"reqs\", title='Time Series with Rangeslider')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
