{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento de dados\n",
    "import pandas as pd\n",
    "df= pd.read_csv('../dados/transformed_data.csv', low_memory=False, index_col=[0])\n",
    "\n",
    "print(\";---------------------;\")\n",
    "print(\"|  Dados Carregados!  |\")\n",
    "print(\"|---------------------|\")\n",
    "print(\"|  df: %d         |\" %len(df))\n",
    "print(\";---------------------;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando fun칞oes\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import html\n",
    "import unidecode\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stopwords = list()\n",
    "    try: stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "    except: nltk.download('stopwords')\n",
    "    stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "    stopwords += ['oi', 'ola', 'opa', 'oie', 'oii', 'oiee', 'oin', 's칩', 'so']\n",
    "    stopwords = [w for w in stopwords if w not in ['mas', 'muito']]\n",
    "    reg_caracters='\\!|\\\"|\\#|\\$|\\%|\\&|\\|\\'|\\(|\\)|\\*|\\+|\\,|\\.|\\/|\\n|\\:|\\;|\\<|\\=|\\>|\\?|\\@|\\[|\\\\|\\]|\\^|\\_|\\`|\\{\\|\\}|\\~|[0-9]*'\n",
    "    remove_acents = lambda sentence: ' '.join([unidecode.unidecode(s) if s.isalnum() else s for s in sentence.split()])\n",
    "\n",
    "    # remove link do texto\n",
    "    text = re.sub(r'http\\S+', '', text) \n",
    "    # adiciona espa칞o no inicio e final do hex-emoji\n",
    "    text = text.replace(\"&#x\", \" &#x\").replace(';', '; ') \n",
    "    # transforma o hex-emoji em emoji\n",
    "    text=html.unescape(text)\n",
    "    # remove caracteres especiais do texto\n",
    "    text = re.sub(reg_caracters, \"\", text)\n",
    "    # remove acentos das palavras preservando \n",
    "    text = remove_acents(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "condictions = lambda pol: [pol < -.45, -.45 <= pol < -.2, -.2 <= pol < .2, .2 <= pol < .45, pol > .45]\n",
    "describes_emojis = {'negativo': \"游땨\", 'irrazoavel': \"游뗴\", 'neutro': \"游땛\", 'razoavel': \"游뗵\", 'positivo': \"游뱔\"}\n",
    "\n",
    "\n",
    "get_polarity = lambda sentence: sia.polarity_scores(sentence, prin_not_lex=False)[0][\"compound\"]\n",
    "get_sentence_size = lambda sentence: len(remove_stopwords(sentence).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An치lise de Sentimentos com custom_vader\n",
    "import sys\n",
    "if '../' not in sys.path: sys.path.append('../')\n",
    "from models.custom_vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sia = SentimentIntensityAnalyzer(\"../dados/custom_vader_lexicon.txt\")\n",
    "print(sia.polarity_scores('eu gostaria ir ao mercado comprar p칚o'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisando msgs\n",
    "test = df[df['from_me']==0].copy()\n",
    "test = test[['protocolo', 'log_texto', 'from_me', 'emojis']]\n",
    "test['polarity'] = test['log_texto'].apply(get_polarity)\n",
    "test['sentence_size'] = test['log_texto'].apply(get_sentence_size)\n",
    "test['class'] = test[\"polarity\"].apply(lambda p: np.select(condictions(p), [*describes_emojis.keys()]) if p is not None else 'indefinido')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Graphs\n",
    "# import plotly.graph_objects as go\n",
    "# from models.graph_tools import Graph\n",
    "\n",
    "# # fig=Graph(test, \"An치lise de Polaridade por qtd. de Palavras\", is_subplot=True, cols=2, cols_width=[.15,.85], rows=1, row_width=[1])\n",
    "# fig=Graph(test, \"An치lise de Polaridade por qtd. de Palavras\")\n",
    "# fig.line('sentence_size', ['polarity'], modes=['markers'], \n",
    "#     marker_colorscale='magenta', \n",
    "#     hovertemplate='p:%{y:,.2f}%<br>w:%{x}'\n",
    "# )\n",
    "# fig.show().update_layout(\n",
    "#     paper_bgcolor='rgba(230,230,230,230)', \n",
    "#     # yaxis={'title': \"Polaridade\", 'range': [-1, 1]},\n",
    "#     xaxis={\"title\":\"Qnd.Palavras na Frase\"},\n",
    "#     title_x=.5\n",
    "# )\n",
    "\n",
    "# # fig.show().update_layout(yaxis_showticklabels=True, yaxis2_showticklabels=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
